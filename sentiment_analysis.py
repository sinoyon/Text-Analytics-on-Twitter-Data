# -*- coding: utf-8 -*-
"""Sentiment_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google
"""

import tweepy
from textblob import TextBlob
from wordcloud import WordCloud
import json
import re
import pandas as pd 
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
from tweepy import OAuthHandler
from tweepy import Stream
from tweepy.streaming import StreamListener 
import os
#os.chdir('F:/SEM_5/NATURAL LANGUAGE PROCESSING/Assignment 3')

consumer_key = "UQ8XFSgXLOSnpm8FLt2ggi0c4"
consumer_secret = "9suCc5INoh69KRflUER83K2kAINYXTkT2gm2jO8LttPKENVJ4M"
access_token = "1111498145177849856-P64xYnQ7LMata8ULOHeMRSmngqsaKA"
access_secret= "ICWLB2vC4CIMrNaGgx6BqbJHqJX2RSCFdAwcCYsxYR4sr"



auth= OAuthHandler(consumer_key,consumer_secret)
auth.set_access_token(access_token,access_secret)
api=tweepy.API(auth)


file= open('flood_raw.dat','a')


class Mylistener(StreamListener):
    def __init__(self, api=None):
        super(StreamListener,self).__init__()
        self.num_tweet = 0
        
    def on_data(self,data):
        try:
            with open('flood_filtered.dat','a') as f:
                tweet=json.loads(data)
                
                if tweet ['lang']=="en":
                    file.write(data)
                    file.write('\n')
                  
                if tweet['lang']=='en' :
                    if self.num_tweet<2000:
                        print(json.dumps(tweet["text"],indent=4))
                        f.write(tweet["text"])
                        f.write("\n")
                        self.num_tweets += 1
                        
                return True
        except BaseException as e:
            print("Error on_data: %s" % str(e))
        return True    
                    
def on_error(self,status):
        print(status)
        return True
def on_status(self,status):
    if status.retweeted_status=='true':
        return
    print(status)
      
mytwitter_stream = Stream(auth,Mylistener())
mytwitter_stream.filter(track=['#banjir', '#flood','#floodmalaysia','#FloodMalaysia', '#FloodRelief','FloodSelangor'])
file.close()
print("done")

posts = api.user_timeline(screen_name="Malaysia", count = 100, lang ="en", tweet_mode="extended")

#  Print the last 5 tweets
print("Show the 5 recent tweets:\n")
i=1
for tweet in posts[:5]:
    print(str(i) +') '+ tweet.full_text + '\n')
    i= i+1

# Create a dataframe with a column called Tweets
df = pd.DataFrame([tweet.full_text for tweet in posts], columns=['Tweets'])
# Show the first 5 rows of data
df.head()

# Create a function to clean the tweets
def cleanTxt(text):
 text = re.sub('@[A-Za-z0â€“9]+', '', text) #Removing @mentions
 text = re.sub('#', '', text) # Removing '#' hash tag
 text = re.sub('RT[\s]+', '', text) # Removing RT
 text = re.sub('https?:\/\/\S+', '', text) # Removing hyperlink
 
 return text


# Clean the tweets
df['Tweets'] = df['Tweets'].apply(cleanTxt)

# Show the cleaned tweets
df

# Create a function to get the subjectivity
def getSubjectivity(text):
   return TextBlob(text).sentiment.subjectivity

# Create a function to get the polarity
def getPolarity(text):
   return  TextBlob(text).sentiment.polarity


# Create two new columns 'Subjectivity' & 'Polarity'
df['Subjectivity'] = df['Tweets'].apply(getSubjectivity)
df['Polarity'] = df['Tweets'].apply(getPolarity)

# Show the new dataframe with columns 'Subjectivity' & 'Polarity'
df

df.info

# word cloud visualization
allWords = ' '.join([twts for twts in df['Tweets']])
wordCloud = WordCloud(width=500, height=300, random_state=21, max_font_size=110).generate(allWords)


plt.imshow(wordCloud, interpolation="bilinear")
plt.axis('off')
plt.show()

# Create a function to compute negative (-1), neutral (0) and positive (+1) analysis
def getAnalysis(score):
    if score < 0:
        return 'Negative'
    elif score == 0:
        return 'Neutral'
    elif score>0:
        if score >=0.4:
            return "Booster"
        else:
            return "positive"

df['Analysis'] = df['Polarity'].apply(getAnalysis)
# Show the dataframe
df

# Printing positive tweets 
print('Printing positive tweets:\n')
j=1
sortedDF = df.sort_values(by=['Polarity']) #Sort the tweets
for i in range(0, sortedDF.shape[0] ):
  if( sortedDF['Analysis'][i] == 'Positive'):
    print(str(j) + ') '+ sortedDF['Tweets'][i])
    print()
    j= j+1

# Printing negative tweets  
print('Printing negative tweets:\n')
j=1
sortedDF = df.sort_values(by=['Polarity'],ascending=False) #Sort the tweets
for i in range(0, sortedDF.shape[0] ):
  if( sortedDF['Analysis'][i] == 'Negative'):
    print(str(j) + ') '+sortedDF['Tweets'][i])
    print()
    j=j+1

# Plotting 
plt.figure(figsize=(8,6)) 
for i in range(0, df.shape[0]):
  plt.scatter(df["Polarity"][i], df["Subjectivity"][i], color='red',alpha=0.5) 
# plt.scatter(x,y,color)   
plt.title('Sentiment Analysis') 
plt.xlabel('Polarity') 
plt.ylabel('Subjectivity') 
plt.show()

# Print the percentage of positive tweets
ptweets = df[df.Analysis == 'Positive']
ptweets = ptweets['Tweets']
ptweets

round( (ptweets.shape[0] / df.shape[0]) * 100 , 1)

# Print the percentage of negative tweets
ntweets = df[df.Analysis == 'Negative']
ntweets = ntweets['Tweets']
ntweets

round( (ntweets.shape[0] / df.shape[0]) * 100, 1)

# Show the value counts
df['Analysis'].value_counts()

# Plotting and visualizing the counts
plt.title('Sentiment Analysis')
plt.xlabel('Sentiment')
plt.ylabel('Counts')
df['Analysis'].value_counts().plot(kind = 'bar',alpha=0.5,color=['b','g','r','y'])
plt.show()

